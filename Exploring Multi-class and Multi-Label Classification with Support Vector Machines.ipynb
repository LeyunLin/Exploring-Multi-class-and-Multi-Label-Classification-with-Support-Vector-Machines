{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Multi-class and Multi-Label Classification with Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Dataset Retrieval:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the Anuran Calls (MFCCs) Data Set from the UCI Machine Learning Repository at:\n",
    "https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29\n",
    ". Randomly designate 70% of the dataset as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../hw7/Frogs_MFCCs.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "X = data.drop(columns=['Family', 'Genus', 'Species'])\n",
    "y = data[['Family', 'Genus', 'Species']]\n",
    "train_size = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_size, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Advanced Classification Strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Metric Assessment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct an in-depth exploration of exact match and Hamming score/loss methods tailored for evaluating multi-label classification. Apply these methodologies to assess classifiers trained for each label using a binary relevance approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss (Family): 1.0\n",
      "Hamming Loss (Genus): 1.0\n",
      "Hamming Loss (Species): 1.0\n",
      "Exact Match Ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "y_train_family = (y_train['Family'] == 'Leptodactylidae').astype(int)\n",
    "y_train_genus = (y_train['Genus'] == 'Adenomera').astype(int)\n",
    "y_train_species = (y_train['Species'] == 'AdenomeraAndre').astype(int)\n",
    "\n",
    "svm_family = SVC()\n",
    "svm_genus = SVC()\n",
    "svm_species = SVC()\n",
    "\n",
    "svm_family.fit(X_train, y_train_family)\n",
    "svm_genus.fit(X_train, y_train_genus)\n",
    "svm_species.fit(X_train, y_train_species)\n",
    "\n",
    "y_pred_family = svm_family.predict(X_test)\n",
    "y_pred_genus = svm_genus.predict(X_test)\n",
    "y_pred_species = svm_species.predict(X_test)\n",
    "\n",
    "hamming_loss_family = hamming_loss(y_test['Family'], y_pred_family)\n",
    "hamming_loss_genus = hamming_loss(y_test['Genus'], y_pred_genus)\n",
    "hamming_loss_species = hamming_loss(y_test['Species'], y_pred_species)\n",
    "\n",
    "exact_match_ratio = ((y_pred_family == y_test['Family']) &\n",
    "                     (y_pred_genus == y_test['Genus']) &\n",
    "                     (y_pred_species == y_test['Species'])).mean()\n",
    "\n",
    "print(f\"Hamming Loss (Family): {hamming_loss_family}\")\n",
    "print(f\"Hamming Loss (Genus): {hamming_loss_genus}\")\n",
    "print(f\"Hamming Loss (Species): {hamming_loss_species}\")\n",
    "print(f\"Exact Match Ratio: {exact_match_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Train a SVM for each of the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the training of Support Vector Machines (SVMs) for each label, employing Gaussian kernels and adopting one-versus-all classifiers. The determination of SVM penalty weight and Gaussian Kernel width will be achieved through rigorous 10-fold cross-validation. Experiments will be conducted with both standardized and raw attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss (Family): 0.0041685965724872626\n",
      "Hamming Loss (Genus): 0.0037054191755442334\n",
      "Hamming Loss (Species): 0.004631773969430292\n",
      "Exact Match Ratio: 0.9925891616489115\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standardized, y, train_size=0.7, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "svm_family = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=10)\n",
    "svm_genus = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=10)\n",
    "svm_species = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=10)\n",
    "\n",
    "svm_family.fit(X_train, y_train['Family'])\n",
    "svm_genus.fit(X_train, y_train['Genus'])\n",
    "svm_species.fit(X_train, y_train['Species'])\n",
    "\n",
    "best_c_family = svm_family.best_params_['C']\n",
    "best_gamma_family = svm_family.best_params_['gamma']\n",
    "\n",
    "best_c_genus = svm_genus.best_params_['C']\n",
    "best_gamma_genus = svm_genus.best_params_['gamma']\n",
    "\n",
    "best_c_species = svm_species.best_params_['C']\n",
    "best_gamma_species = svm_species.best_params_['gamma']\n",
    "y_pred_family = svm_family.predict(X_test)\n",
    "y_pred_genus = svm_genus.predict(X_test)\n",
    "y_pred_species = svm_species.predict(X_test)\n",
    "\n",
    "hamming_loss_family = hamming_loss(y_test['Family'], y_pred_family)\n",
    "hamming_loss_genus = hamming_loss(y_test['Genus'], y_pred_genus)\n",
    "hamming_loss_species = hamming_loss(y_test['Species'], y_pred_species)\n",
    "\n",
    "exact_match_ratio = ((y_pred_family == y_test['Family']) &\n",
    "                     (y_pred_genus == y_test['Genus']) &\n",
    "                     (y_pred_species == y_test['Species'])).mean()\n",
    "\n",
    "print(f\"Hamming Loss (Family): {hamming_loss_family}\")\n",
    "print(f\"Hamming Loss (Genus): {hamming_loss_genus}\")\n",
    "print(f\"Hamming Loss (Species): {hamming_loss_species}\")\n",
    "print(f\"Exact Match Ratio: {exact_match_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii)  L1-Penalized SVMs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat SVM training, introducing L1-penalized SVMs into the mix. Standardize attributes and ascertain the penalty weight through meticulous 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C (penalty) for L1-penalized SVMs:\n",
      "C (Family): 100\n",
      "C (Genus): 100\n",
      "C (Species): 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "l1_svm_family = GridSearchCV(LinearSVC(penalty='l1', dual=False, max_iter=10000), param_grid, cv=10)\n",
    "l1_svm_genus = GridSearchCV(LinearSVC(penalty='l1', dual=False, max_iter=10000), param_grid, cv=10)\n",
    "l1_svm_species = GridSearchCV(LinearSVC(penalty='l1', dual=False, max_iter=10000), param_grid, cv=10)\n",
    "\n",
    "l1_svm_family.fit(X_train, y_train['Family'])\n",
    "l1_svm_genus.fit(X_train, y_train['Genus'])\n",
    "l1_svm_species.fit(X_train, y_train['Species'])\n",
    "\n",
    "best_c_l1_family = l1_svm_family.best_params_['C']\n",
    "best_c_l1_genus = l1_svm_genus.best_params_['C']\n",
    "best_c_l1_species = l1_svm_species.best_params_['C']\n",
    "\n",
    "print(\"Best C (penalty) for L1-penalized SVMs:\")\n",
    "print(f\"C (Family): {best_c_l1_family}\")\n",
    "print(f\"C (Genus): {best_c_l1_genus}\")\n",
    "print(f\"C (Species): {best_c_l1_species}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Tackling Class Imbalance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the L1-penalized SVM training to address class imbalance, utilizing methodologies such as SMOTE or other suitable techniques. Subsequently, draw insightful conclusions based on the performance of the trained classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss with SMOTE:\n",
      "Hamming Loss (Family): 1.0\n",
      "Hamming Loss (Genus): 1.0\n",
      "Hamming Loss (Species): 1.0\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_resampled_family, y_resampled_family = smote.fit_resample(X_train, y_train_family)\n",
    "X_resampled_genus, y_resampled_genus = smote.fit_resample(X_train, y_train_genus)\n",
    "X_resampled_species, y_resampled_species = smote.fit_resample(X_train, y_train_species)\n",
    "\n",
    "svm_family_smote = SVC()\n",
    "svm_genus_smote = SVC()\n",
    "svm_species_smote = SVC()\n",
    "\n",
    "svm_family_smote.fit(X_resampled_family, y_resampled_family)\n",
    "svm_genus_smote.fit(X_resampled_genus, y_resampled_genus)\n",
    "svm_species_smote.fit(X_resampled_species, y_resampled_species)\n",
    "\n",
    "y_pred_family_smote = svm_family_smote.predict(X_test)\n",
    "y_pred_genus_smote = svm_genus_smote.predict(X_test)\n",
    "y_pred_species_smote = svm_species_smote.predict(X_test)\n",
    "\n",
    "hamming_loss_family_smote = hamming_loss(y_test['Family'], y_pred_family_smote)\n",
    "hamming_loss_genus_smote = hamming_loss(y_test['Genus'], y_pred_genus_smote)\n",
    "hamming_loss_species_smote = hamming_loss(y_test['Species'], y_pred_species_smote)\n",
    "\n",
    "print(\"Hamming Loss with SMOTE:\")\n",
    "print(f\"Hamming Loss (Family): {hamming_loss_family_smote}\")\n",
    "print(f\"Hamming Loss (Genus): {hamming_loss_genus_smote}\")\n",
    "print(f\"Hamming Loss (Species): {hamming_loss_species_smote}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) k-means clustering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the k-means clustering algorithm to the entire Anuran Calls (MFCCs) Data Set without the conventional train-test data split. The optimal value of k will be automatically determined from the set {1, 2, ..., 50} using established methods like CH, Gap Statistics, scree plots, Silhouettes, or any other recognized approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Silhouette Score over 50 simulations: 0.25224160686272257\n",
      "Standard Deviation of Silhouette Score over 50 simulations: 0.03651893756582283\n"
     ]
    }
   ],
   "source": [
    "file_path = '../hw7/Frogs_MFCCs.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "X = data.drop(columns=['Family', 'Genus', 'Species'])\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "num_simulations = 50\n",
    "silhouette_scores = []\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    for k in range(2, 51):  # Start with k=2 to ensure at least two clusters\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(X_standardized)\n",
    "        cluster_labels = kmeans.labels_\n",
    "        silhouette_avg = silhouette_score(X_standardized, cluster_labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "average_silhouette_score = np.mean(silhouette_scores)\n",
    "std_deviation_silhouette_score = np.std(silhouette_scores)\n",
    "\n",
    "print(f\"Average Silhouette Score over {num_simulations} simulations: {average_silhouette_score}\")\n",
    "print(f\"Standard Deviation of Silhouette Score over {num_simulations} simulations: {std_deviation_silhouette_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Majority Label Identification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within each cluster, ascertain the majority labels for family, genus, and species by referencing the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 - Majority Family: Leptodactylidae, Majority Genus: Adenomera, Majority Species: AdenomeraHylaedactylus\n",
      "Cluster 2 - Majority Family: Hylidae, Majority Genus: Hypsiboas, Majority Species: HypsiboasCinerascens\n",
      "Cluster 3 - Majority Family: Leptodactylidae, Majority Genus: Adenomera, Majority Species: AdenomeraAndre\n",
      "Cluster 4 - Majority Family: Hylidae, Majority Genus: Hypsiboas, Majority Species: HypsiboasCordobae\n",
      "Cluster 5 - Majority Family: Leptodactylidae, Majority Genus: Adenomera, Majority Species: AdenomeraAndre\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "file_path = 'Frogs_MFCCs.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "X = data.drop(columns=['Family', 'Genus', 'Species'])\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X_standardized)\n",
    "data['Cluster'] = kmeans.labels_\n",
    "\n",
    "def majority_label(cluster_df, label_column):\n",
    "    counts = cluster_df[label_column].value_counts()\n",
    "    majority_label = counts.idxmax()\n",
    "    return majority_label\n",
    "\n",
    "majority_families = []\n",
    "majority_genus = []\n",
    "majority_species = []\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_data = data[data['Cluster'] == cluster]\n",
    "    \n",
    "    majority_family = majority_label(cluster_data, 'Family')\n",
    "    majority_genus_cluster = majority_label(cluster_data, 'Genus')\n",
    "    majority_species_cluster = majority_label(cluster_data, 'Species')\n",
    "    \n",
    "    majority_families.append(majority_family)\n",
    "    majority_genus.append(majority_genus_cluster)\n",
    "    majority_species.append(majority_species_cluster)\n",
    "for cluster in range(k):\n",
    "    print(f\"Cluster {cluster + 1} - Majority Family: {majority_families[cluster]}, Majority Genus: {majority_genus[cluster]}, Majority Species: {majority_species[cluster]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Hamming Distance Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average Hamming distance, Hamming score, and Hamming loss between the true labels and labels assigned by clusters for each cluster, providing insights into the efficacy of the K-Means Clustering approach in a multi-class and multi-label context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Hamming Distance (Family): 0.24500646025791079\n",
      "Average Hamming Score (Family): 0.7549935397420893\n",
      "Average Hamming Distance (Genus): 0.3062812003914012\n",
      "Average Hamming Score (Genus): 0.6937187996085987\n",
      "Average Hamming Distance (Species): 0.3272723139624235\n",
      "Average Hamming Score (Species): 0.6727276860375765\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X_standardized)\n",
    "\n",
    "data['Cluster'] = kmeans.labels_\n",
    "\n",
    "def calculate_hamming_metrics(cluster_df, label_column, majority_labels):\n",
    "    true_labels = cluster_df[label_column].values\n",
    "    cluster_labels = np.array([majority_labels[cluster_df['Cluster'].iloc[i]] for i in range(len(cluster_df))])\n",
    "    \n",
    "    hamming_distance = hamming_loss(true_labels, cluster_labels)\n",
    "    hamming_score = 1.0 - hamming_distance\n",
    "    \n",
    "    return hamming_distance, hamming_score\n",
    "\n",
    "majority_labels = {}\n",
    "\n",
    "for label_column in ['Family', 'Genus', 'Species']:\n",
    "    majority_labels[label_column] = []\n",
    "    for cluster in range(k):\n",
    "        cluster_data = data[data['Cluster'] == cluster]\n",
    "        majority_label = cluster_data[label_column].mode().values[0]\n",
    "        majority_labels[label_column].append(majority_label)\n",
    "\n",
    "cluster_labels_df = data[['Family', 'Genus', 'Species', 'Cluster']]\n",
    "\n",
    "hamming_distance_dict = {}\n",
    "hamming_score_dict = {}\n",
    "\n",
    "for label_column in ['Family', 'Genus', 'Species']:\n",
    "    hamming_distance_list = []\n",
    "    hamming_score_list = []\n",
    "\n",
    "    for cluster in range(k):\n",
    "        cluster_data = cluster_labels_df[cluster_labels_df['Cluster'] == cluster]\n",
    "        hamming_distance, hamming_score = calculate_hamming_metrics(cluster_data, label_column, majority_labels[label_column])\n",
    "\n",
    "        hamming_distance_list.append(hamming_distance)\n",
    "        hamming_score_list.append(hamming_score)\n",
    "\n",
    "    average_hamming_distance = np.mean(hamming_distance_list)\n",
    "    average_hamming_score = np.mean(hamming_score_list)\n",
    "\n",
    "    hamming_distance_dict[label_column] = average_hamming_distance\n",
    "    hamming_score_dict[label_column] = average_hamming_score\n",
    "\n",
    "for label_column in ['Family', 'Genus', 'Species']:\n",
    "    print(f\"Average Hamming Distance ({label_column}): {hamming_distance_dict[label_column]}\")\n",
    "    print(f\"Average Hamming Score ({label_column}): {hamming_score_dict[label_column]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
